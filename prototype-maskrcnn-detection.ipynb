{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8924904,"sourceType":"datasetVersion","datasetId":5368425},{"sourceId":8939317,"sourceType":"datasetVersion","datasetId":5325385},{"sourceId":9052972,"sourceType":"datasetVersion","datasetId":5458563}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/razyrick/Mask-RCNN_TF2.14.0\n%cd Mask-RCNN_TF2.14.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-12T02:24:08.393029Z","iopub.execute_input":"2024-11-12T02:24:08.393937Z","iopub.status.idle":"2024-11-12T02:24:12.614129Z","shell.execute_reply.started":"2024-11-12T02:24:08.393890Z","shell.execute_reply":"2024-11-12T02:24:12.612962Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Cloning into 'Mask-RCNN_TF2.14.0'...\nremote: Enumerating objects: 234, done.\u001b[K\nremote: Counting objects: 100% (41/41), done.\u001b[K\nremote: Compressing objects: 100% (26/26), done.\u001b[K\nremote: Total 234 (delta 27), reused 15 (delta 15), pack-reused 193 (from 1)\u001b[K\nReceiving objects: 100% (234/234), 74.90 MiB | 38.25 MiB/s, done.\nResolving deltas: 100% (75/75), done.\n/kaggle/working/Mask-RCNN_TF2.14.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -r requirements.txt\n!python3 -m pip install tensorflow[and-cuda]","metadata":{"execution":{"iopub.status.busy":"2024-11-12T02:24:12.616637Z","iopub.execute_input":"2024-11-12T02:24:12.616935Z","iopub.status.idle":"2024-11-12T02:27:55.165886Z","shell.execute_reply.started":"2024-11-12T02:24:12.616902Z","shell.execute_reply":"2024-11-12T02:27:55.164772Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting cython==3.0.5 (from -r requirements.txt (line 1))\n  Downloading Cython-3.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nCollecting h5py==3.9.0 (from -r requirements.txt (line 2))\n  Downloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nRequirement already satisfied: imgaug==0.4.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.4.0)\nCollecting ipython==7.34.0 (from -r requirements.txt (line 4))\n  Downloading ipython-7.34.0-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: ipython-genutils==0.2.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.2.0)\nRequirement already satisfied: ipython-sql==0.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.5.0)\nCollecting keras==2.14.0 (from -r requirements.txt (line 7))\n  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting matplotlib==3.7.1 (from -r requirements.txt (line 8))\n  Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nCollecting numpy==1.23.5 (from -r requirements.txt (line 9))\n  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\nCollecting opencv-contrib-python==4.8.0.76 (from -r requirements.txt (line 10))\n  Downloading opencv_contrib_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nCollecting opencv-python==4.8.0.76 (from -r requirements.txt (line 11))\n  Downloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nCollecting pillow==9.4.0 (from -r requirements.txt (line 12))\n  Downloading Pillow-9.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.3 kB)\nCollecting scikit-image==0.19.3 (from -r requirements.txt (line 13))\n  Downloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\nCollecting scipy==1.11.3 (from -r requirements.txt (line 14))\n  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tensorboard==2.14.1 (from -r requirements.txt (line 15))\n  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\nCollecting tensorflow==2.14.0 (from -r requirements.txt (line 16))\n  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0->-r requirements.txt (line 3)) (1.16.0)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0->-r requirements.txt (line 3)) (2.34.1)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0->-r requirements.txt (line 3)) (1.8.5.post1)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.10/site-packages (from ipython==7.34.0->-r requirements.txt (line 4)) (70.0.0)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython==7.34.0->-r requirements.txt (line 4)) (0.19.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython==7.34.0->-r requirements.txt (line 4)) (5.1.1)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython==7.34.0->-r requirements.txt (line 4)) (0.7.5)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.10/site-packages (from ipython==7.34.0->-r requirements.txt (line 4)) (5.14.3)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from ipython==7.34.0->-r requirements.txt (line 4)) (3.0.47)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.10/site-packages (from ipython==7.34.0->-r requirements.txt (line 4)) (2.18.0)\nCollecting backcall (from ipython==7.34.0->-r requirements.txt (line 4))\n  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython==7.34.0->-r requirements.txt (line 4)) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython==7.34.0->-r requirements.txt (line 4)) (4.9.0)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from ipython-sql==0.5.0->-r requirements.txt (line 6)) (3.10.0)\nRequirement already satisfied: sqlalchemy>=2.0 in /opt/conda/lib/python3.10/site-packages (from ipython-sql==0.5.0->-r requirements.txt (line 6)) (2.0.30)\nRequirement already satisfied: sqlparse in /opt/conda/lib/python3.10/site-packages (from ipython-sql==0.5.0->-r requirements.txt (line 6)) (0.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 8)) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 8)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 8)) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 8)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 8)) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 8)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 8)) (2.9.0.post0)\nRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.10/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 13)) (3.3)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 13)) (2024.5.22)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 13)) (1.6.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.14.1->-r requirements.txt (line 15)) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.14.1->-r requirements.txt (line 15)) (1.62.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.14.1->-r requirements.txt (line 15)) (2.30.0)\nCollecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard==2.14.1->-r requirements.txt (line 15))\n  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.14.1->-r requirements.txt (line 15)) (3.6)\nRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.14.1->-r requirements.txt (line 15)) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.14.1->-r requirements.txt (line 15)) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.14.1->-r requirements.txt (line 15)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.14.1->-r requirements.txt (line 15)) (3.0.3)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.0->-r requirements.txt (line 16)) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.0->-r requirements.txt (line 16)) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.0->-r requirements.txt (line 16)) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.0->-r requirements.txt (line 16)) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.0->-r requirements.txt (line 16)) (18.1.1)\nCollecting ml-dtypes==0.2.0 (from tensorflow==2.14.0->-r requirements.txt (line 16))\n  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.0->-r requirements.txt (line 16)) (3.3.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.0->-r requirements.txt (line 16)) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.0->-r requirements.txt (line 16)) (4.12.2)\nCollecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0->-r requirements.txt (line 16))\n  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.14.0->-r requirements.txt (line 16)) (0.37.0)\nCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0->-r requirements.txt (line 16))\n  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.14.0->-r requirements.txt (line 16)) (0.43.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.14.1->-r requirements.txt (line 15)) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.14.1->-r requirements.txt (line 15)) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.14.1->-r requirements.txt (line 15)) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard==2.14.1->-r requirements.txt (line 15)) (2.0.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython==7.34.0->-r requirements.txt (line 4)) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython==7.34.0->-r requirements.txt (line 4)) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->-r requirements.txt (line 4)) (0.2.13)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.14.1->-r requirements.txt (line 15)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.14.1->-r requirements.txt (line 15)) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.14.1->-r requirements.txt (line 15)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.14.1->-r requirements.txt (line 15)) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=2.0->ipython-sql==0.5.0->-r requirements.txt (line 6)) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard==2.14.1->-r requirements.txt (line 15)) (2.1.5)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.14.1->-r requirements.txt (line 15)) (0.6.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard==2.14.1->-r requirements.txt (line 15)) (3.2.2)\nDownloading Cython-3.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ipython-7.34.0-py3-none-any.whl (793 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opencv_contrib_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading Pillow-9.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\nDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: backcall, wrapt, tensorflow-estimator, pillow, numpy, keras, cython, scipy, opencv-python, opencv-contrib-python, ml-dtypes, ipython, h5py, scikit-image, matplotlib, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.16.0\n    Uninstalling wrapt-1.16.0:\n      Successfully uninstalled wrapt-1.16.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.15.0\n    Uninstalling tensorflow-estimator-2.15.0:\n      Successfully uninstalled tensorflow-estimator-2.15.0\n  Attempting uninstall: pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n  Attempting uninstall: cython\n    Found existing installation: Cython 3.0.10\n    Uninstalling Cython-3.0.10:\n      Successfully uninstalled Cython-3.0.10\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.14.0\n    Uninstalling scipy-1.14.0:\n      Successfully uninstalled scipy-1.14.0\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.10.0.84\n    Uninstalling opencv-python-4.10.0.84:\n      Successfully uninstalled opencv-python-4.10.0.84\n  Attempting uninstall: opencv-contrib-python\n    Found existing installation: opencv-contrib-python 4.10.0.84\n    Uninstalling opencv-contrib-python-4.10.0.84:\n      Successfully uninstalled opencv-contrib-python-4.10.0.84\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.3.2\n    Uninstalling ml-dtypes-0.3.2:\n      Successfully uninstalled ml-dtypes-0.3.2\n  Attempting uninstall: ipython\n    Found existing installation: ipython 8.21.0\n    Uninstalling ipython-8.21.0:\n      Successfully uninstalled ipython-8.21.0\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.11.0\n    Uninstalling h5py-3.11.0:\n      Successfully uninstalled h5py-3.11.0\n  Attempting uninstall: scikit-image\n    Found existing installation: scikit-image 0.23.2\n    Uninstalling scikit-image-0.23.2:\n      Successfully uninstalled scikit-image-0.23.2\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.5\n    Uninstalling matplotlib-3.7.5:\n      Successfully uninstalled matplotlib-3.7.5\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.16.2\n    Uninstalling tensorboard-2.16.2:\n      Successfully uninstalled tensorboard-2.16.2\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.16.1\n    Uninstalling tensorflow-2.16.1:\n      Successfully uninstalled tensorflow-2.16.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.2 requires cubinlinker, which is not installed.\ncudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.2 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\nucxx 0.39.1 requires libucx>=1.15.0, which is not installed.\nalbucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.23.5 which is incompatible.\nalbumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\nalbumentations 1.4.14 requires scikit-image>=0.21.0, but you have scikit-image 0.19.3 which is incompatible.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\nbayesian-optimization 1.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\nbeatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.4 which is incompatible.\nchex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\ncudf 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nfitter 1.7.1 requires matplotlib<4.0.0,>=3.7.2, but you have matplotlib 3.7.1 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\njupyterlab 4.2.4 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.4 requires shapely<2.1,>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\nrmm 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.14.0 which is incompatible.\ntensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.14.0 which is incompatible.\ntensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.14.0 which is incompatible.\ntensorstore 0.1.64 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\ntf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.14.0 which is incompatible.\ntsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.3 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nxarray 2024.7.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed backcall-0.2.0 cython-3.0.5 google-auth-oauthlib-1.0.0 h5py-3.9.0 ipython-7.34.0 keras-2.14.0 matplotlib-3.7.1 ml-dtypes-0.2.0 numpy-1.23.5 opencv-contrib-python-4.8.0.76 opencv-python-4.8.0.76 pillow-9.4.0 scikit-image-0.19.3 scipy-1.11.3 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 wrapt-1.14.1\nRequirement already satisfied: tensorflow[and-cuda] in /opt/conda/lib/python3.10/site-packages (2.14.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.9.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (18.1.1)\nRequirement already satisfied: ml-dtypes==0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\nRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (4.12.2)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.37.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.62.2)\nRequirement already satisfied: tensorboard<2.15,>=2.14 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.14.1)\nRequirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.14.0)\nRequirement already satisfied: keras<2.15,>=2.14.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.14.0)\nCollecting nvidia-cuda-runtime-cu11==11.8.89 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cublas-cu11==11.11.3.6 (from tensorflow[and-cuda])\n  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from tensorflow[and-cuda])\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cudnn-cu11==8.7.0.84 (from tensorflow[and-cuda])\n  Downloading nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-curand-cu11==10.3.0.86 (from tensorflow[and-cuda])\n  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu11==11.4.1.48 (from tensorflow[and-cuda])\n  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.5.86 (from tensorflow[and-cuda])\n  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-nccl-cu11==2.16.5 (from tensorflow[and-cuda])\n  Downloading nvidia_nccl_cu11-2.16.5-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cuda-cupti-cu11==11.8.87 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-nvcc-cu11==11.8.89 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting tensorrt==8.5.3.1 (from tensorflow[and-cuda])\n  Downloading tensorrt-8.5.3.1-cp310-none-manylinux_2_17_x86_64.whl.metadata (721 bytes)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.43.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.30.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow[and-cuda]) (3.1.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.1.5)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (0.6.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.2.2)\nDownloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (19.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu11-2.16.5-py3-none-manylinux1_x86_64.whl (210.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorrt-8.5.3.1-cp310-none-manylinux_2_17_x86_64.whl (549.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.5/549.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvcc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, tensorrt\nSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvcc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.16.5 tensorrt-8.5.3.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install setuptools==58.2.0\n!python3 setup.py install","metadata":{"execution":{"iopub.status.busy":"2024-11-12T02:27:55.167396Z","iopub.execute_input":"2024-11-12T02:27:55.167739Z","iopub.status.idle":"2024-11-12T02:28:16.289151Z","shell.execute_reply.started":"2024-11-12T02:27:55.167690Z","shell.execute_reply":"2024-11-12T02:28:16.288009Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting setuptools==58.2.0\n  Downloading setuptools-58.2.0-py3-none-any.whl.metadata (4.9 kB)\nDownloading setuptools-58.2.0-py3-none-any.whl (946 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m946.1/946.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: setuptools\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 70.0.0\n    Uninstalling setuptools-70.0.0:\n      Successfully uninstalled setuptools-70.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\narviz 0.19.0 requires setuptools>=60.0.0, but you have setuptools 58.2.0 which is incompatible.\nconda 24.7.1 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\nconda 24.7.1 requires setuptools>=60.0.0, but you have setuptools 58.2.0 which is incompatible.\njupyterlab 4.2.4 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\ntensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.14.0 which is incompatible.\ntensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.14.0 which is incompatible.\ntensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.14.0 which is incompatible.\ntf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed setuptools-58.2.0\n/opt/conda/lib/python3.10/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'license-file' will not be supported in future versions. Please use the underscore name 'license_file' instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'requirements-file' will not be supported in future versions. Please use the underscore name 'requirements_file' instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/setuptools_scm/_integration/setuptools.py:31: RuntimeWarning: \nERROR: setuptools==58.2.0 is used in combination with setuptools_scm>=8.x\n\nYour build configuration is incomplete and previously worked by accident!\nsetuptools_scm requires setuptools>=61\n\nSuggested workaround if applicable:\n - migrating from the deprecated setup_requires mechanism to pep517/518\n   and using a pyproject.toml to declare build dependencies\n   which are reliably pre-installed before running the build tools\n\n  warnings.warn(\nrunning install\nrunning bdist_egg\nrunning egg_info\ncreating mask_rcnn_tf2.egg-info\nwriting mask_rcnn_tf2.egg-info/PKG-INFO\nwriting dependency_links to mask_rcnn_tf2.egg-info/dependency_links.txt\nwriting top-level names to mask_rcnn_tf2.egg-info/top_level.txt\nwriting manifest file 'mask_rcnn_tf2.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nadding license file 'LICENSE'\nwriting manifest file 'mask_rcnn_tf2.egg-info/SOURCES.txt'\ninstalling library code to build/bdist.linux-x86_64/egg\nrunning install_lib\nrunning build_py\ncreating build\ncreating build/lib\ncreating build/lib/mrcnn\ncopying mrcnn/config.py -> build/lib/mrcnn\ncopying mrcnn/__init__.py -> build/lib/mrcnn\ncopying mrcnn/model.py -> build/lib/mrcnn\ncopying mrcnn/parallel_model.py -> build/lib/mrcnn\ncopying mrcnn/utils.py -> build/lib/mrcnn\ncopying mrcnn/visualize.py -> build/lib/mrcnn\ncreating build/bdist.linux-x86_64\ncreating build/bdist.linux-x86_64/egg\ncreating build/bdist.linux-x86_64/egg/mrcnn\ncopying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\ncopying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\ncopying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\ncopying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\ncopying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\ncopying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\nbyte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-310.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-310.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-310.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-310.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-310.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-310.pyc\ncreating build/bdist.linux-x86_64/egg/EGG-INFO\ncopying mask_rcnn_tf2.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying mask_rcnn_tf2.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying mask_rcnn_tf2.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying mask_rcnn_tf2.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\nzip_safe flag not set; analyzing archive contents...\ncreating dist\ncreating 'dist/mask_rcnn_tf2-1.0-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\nremoving 'build/bdist.linux-x86_64/egg' (and everything under it)\nProcessing mask_rcnn_tf2-1.0-py3.10.egg\nCopying mask_rcnn_tf2-1.0-py3.10.egg to /opt/conda/lib/python3.10/site-packages\nAdding mask-rcnn-tf2 1.0 to easy-install.pth file\n\nInstalled /opt/conda/lib/python3.10/site-packages/mask_rcnn_tf2-1.0-py3.10.egg\nProcessing dependencies for mask-rcnn-tf2==1.0\nFinished processing dependencies for mask-rcnn-tf2==1.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install git+https://github.com/facebookresearch/segment-anything.git\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118","metadata":{"execution":{"iopub.status.busy":"2024-11-12T02:28:16.290909Z","iopub.execute_input":"2024-11-12T02:28:16.291833Z","iopub.status.idle":"2024-11-12T02:28:44.542593Z","shell.execute_reply.started":"2024-11-12T02:28:16.291781Z","shell.execute_reply":"2024-11-12T02:28:44.541621Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/facebookresearch/segment-anything.git\n  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-w530jg7u\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-w530jg7u\n  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hLooking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#prototype_utils\n\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n#single image\ndef show_mask(mask, ax, random_color=False):\n    if random_color:\n        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n    else:\n        color = np.array([30/255, 144/255, 255/255, 0.6])\n    h, w = mask.shape[-2:]\n    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n    ax.imshow(mask_image)\n    \ndef show_points(coords, labels, ax, marker_size=375):\n    pos_points = coords[labels==1]\n    neg_points = coords[labels==0]\n    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n    \ndef show_box(box, ax):\n    x0, y0 = box[0], box[1]\n    w, h = box[2] - box[0], box[3] - box[1]\n    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n\ndef transform_yxyx_to_xyxy(yxyx_boxes):\n    xyxy_boxes = []\n    for box in yxyx_boxes:\n        y1, x1, y2, x2 = box\n        xyxy_boxes.append([x1, y1, x2, y2])\n    return xyxy_boxes\n\ndef crop_object_from_image(image, mask):\n    mask = mask.astype(np.uint8)\n    mask = np.squeeze(mask)\n    y_indices, x_indices = np.where(mask)\n    if len(y_indices) == 0 or len(x_indices) == 0:\n        return None\n    y1, y2 = y_indices.min(), y_indices.max()\n    x1, x2 = x_indices.min(), x_indices.max()\n    cropped_image = image[y1:y2 + 1, x1:x2 + 1]\n    cropped_mask = mask[y1:y2 + 1, x1:x2 + 1]\n    if len(cropped_image.shape) == 2 or cropped_image.shape[2] == 1:\n        cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_GRAY2RGB)\n    rgba_image = cv2.cvtColor(cropped_image, cv2.COLOR_RGB2RGBA)\n    rgba_image[:, :, 3] = cropped_mask * 255\n    return rgba_image\n\ndef resize_and_pad_image(image, target_size):\n    h, w = image.shape[:2]\n    target_h, target_w = target_size\n    scale = min(target_w / w, target_h / h)\n    new_w, new_h = int(w * scale), int(h * scale)\n    resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n    padded_image = np.zeros((target_h, target_w, 4), dtype=np.uint8)\n    pad_w = (target_w - new_w) // 2\n    pad_h = (target_h - new_h) // 2\n    padded_image[pad_h:pad_h + new_h, pad_w:pad_w + new_w] = resized_image\n    return padded_image\n\ndef remove_alpha_channel(image):\n    if image.shape[-1] == 4:\n        return cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-11-12T02:28:44.545116Z","iopub.execute_input":"2024-11-12T02:28:44.545446Z","iopub.status.idle":"2024-11-12T02:28:44.635886Z","shell.execute_reply.started":"2024-11-12T02:28:44.545411Z","shell.execute_reply":"2024-11-12T02:28:44.634967Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\"\"\"import ipywidgets as widgets\nfrom IPython.display import display\nfrom PIL import Image, ImageDraw\nimport numpy as np\nimport torch\nimport skimage.io\nimport io\nimport os\nfrom mrcnn.config import Config\nfrom mrcnn.model import MaskRCNN\nfrom segment_anything import SamPredictor, sam_model_registry\n\n# Load the Mask R-CNN model\nclass InferenceConfig(Config):\n    NAME = \"coco\"\n    IMAGES_PER_GPU = 1\n    NUM_CLASSES = 1 + 1  # Background + coconut\n    GPU_COUNT = 1\n\nconfig = InferenceConfig()\nmodel = MaskRCNN(mode=\"inference\", model_dir=\"/path/to/logs\", config=config)\nmodel.load_weights(\"/kaggle/input/cocooo/mask_rcnn_custom_0015.h5\", by_name=True)\n\ncheckpoint = \"/kaggle/input/samvith/sam_vit_h_4b8939.pth\"\nmodel_type = \"vit_h\"\nsam = sam_model_registry[model_type](checkpoint=checkpoint).cuda()\npredictor = SamPredictor(sam)\n\n# Function to draw bounding boxes and masks on the image\ndef draw_boxes_and_masks(original_image, rois, masks, mask_opacity=0.5):\n    original_image = original_image.convert(\"RGBA\")\n    mask_image = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n    \n    for i, roi in enumerate(rois):\n        y1, x1, y2, x2 = roi\n        draw = ImageDraw.Draw(original_image)\n        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n\n        mask = masks[i]\n        mask_image_part = Image.fromarray((mask * 255).astype(np.uint8)).convert(\"L\")\n        mask_with_opacity = Image.new(\"RGBA\", mask_image.size, (255, 255, 255, 0))\n        \n        for x in range(mask_image_part.width):\n            for y in range(mask_image_part.height):\n                if mask_image_part.getpixel((x, y)) > 0:\n                    mask_with_opacity.putpixel((x, y), (255, 0, 0, int(255 * mask_opacity)))\n        \n        mask_image = Image.alpha_composite(mask_image, mask_with_opacity)\n\n    return Image.alpha_composite(original_image, mask_image).convert(\"RGB\")\n\n\n# Function to run the prediction\ndef run_prediction(img_file):\n    target_size = (224, 224)\n    image = skimage.io.imread(img_file)\n    image = remove_alpha_channel(image)\n\n    results = model.detect([image], verbose=1)\n    r = results[0]\n    \n    confidence_threshold = 0.9\n    filtered_indices = np.where(r['scores'] >= confidence_threshold)[0]\n    filtered_rois = r['rois'][filtered_indices]\n    \n    predictor.set_image(image)\n    filtered_rois_xyxy = transform_yxyx_to_xyxy(filtered_rois)\n    input_boxes = torch.tensor(filtered_rois_xyxy, device=predictor.device)\n    transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])  \n\n    save_path = \"/kaggle/working/cropped\"\n    os.makedirs(save_path, exist_ok=True)\n    \n    masks_list = []\n    \n    for j, box in enumerate(transformed_boxes):\n        masks, scores, _ = predictor.predict_torch(\n            boxes=torch.unsqueeze(box, 0),\n            point_coords=None,\n            point_labels=None,\n            multimask_output=True\n        )\n\n        if masks.shape[0] > 0:\n            highest_score_index = torch.argmax(scores)\n            highest_score_mask = masks[0][highest_score_index].cpu().numpy()\n            masks_list.append(highest_score_mask)\n            \n            cropped_image = crop_object_from_image(image, highest_score_mask)\n\n            if cropped_image is None:\n                print(f\"No object found in mask {j} for image {img_file}\")\n                continue\n\n            resized_padded_image = resize_and_pad_image(cropped_image, target_size)\n            filename = os.path.splitext(os.path.basename(img_file))[0]\n            skimage.io.imsave(os.path.join(save_path, f'cropped_image_{filename}_{j}.png'), resized_padded_image)\n        else:\n            print(f\"No masks returned for box {j} in image {img_file}\")\n\n    original_image = Image.fromarray(image)\n    \n    if masks_list:\n        image_with_boxes = draw_boxes_and_masks(original_image.copy(), filtered_rois, masks_list)\n    else:\n        image_with_boxes = original_image.copy()\n\n    return image_with_boxes\n\n\n# Create widgets for the interface\nfile_upload = widgets.FileUpload(accept='.jpg,.jpeg,.png', multiple=False)\noutput = widgets.Output()\n\n# Function to handle file upload and display prediction\ndef on_file_upload(change):\n    for file_name, file_info in file_upload.value.items():\n        with output:\n            output.clear_output()\n            \n            img_data = file_info['content']\n            img = Image.open(io.BytesIO(img_data))\n            img.thumbnail((244, 244))\n            \n            # Display original image\n            display(widgets.Image(value=img_data, format='png'))\n            \n            # Save to disk for model processing\n            img_path = f\"/kaggle/working/{file_name}\"\n            with open(img_path, 'wb') as f:\n                f.write(img_data)\n            \n            # Run the prediction\n            image_with_boxes = run_prediction(img_path)\n            \n            # Display processed image with boxes\n            processed_img_bytes = io.BytesIO()\n            image_with_boxes.save(processed_img_bytes, format='PNG')\n            processed_img_bytes.seek(0)\n            display(widgets.Image(value=processed_img_bytes.read(), format='png'))\n\n\nfile_upload.observe(on_file_upload, names='value')\n\n# Display the UI\ndisplay(file_upload, output)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-11-12T02:28:44.637309Z","iopub.execute_input":"2024-11-12T02:28:44.637915Z","iopub.status.idle":"2024-11-12T02:28:44.652556Z","shell.execute_reply.started":"2024-11-12T02:28:44.637871Z","shell.execute_reply":"2024-11-12T02:28:44.651693Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'import ipywidgets as widgets\\nfrom IPython.display import display\\nfrom PIL import Image, ImageDraw\\nimport numpy as np\\nimport torch\\nimport skimage.io\\nimport io\\nimport os\\nfrom mrcnn.config import Config\\nfrom mrcnn.model import MaskRCNN\\nfrom segment_anything import SamPredictor, sam_model_registry\\n\\n# Load the Mask R-CNN model\\nclass InferenceConfig(Config):\\n    NAME = \"coco\"\\n    IMAGES_PER_GPU = 1\\n    NUM_CLASSES = 1 + 1  # Background + coconut\\n    GPU_COUNT = 1\\n\\nconfig = InferenceConfig()\\nmodel = MaskRCNN(mode=\"inference\", model_dir=\"/path/to/logs\", config=config)\\nmodel.load_weights(\"/kaggle/input/cocooo/mask_rcnn_custom_0015.h5\", by_name=True)\\n\\ncheckpoint = \"/kaggle/input/samvith/sam_vit_h_4b8939.pth\"\\nmodel_type = \"vit_h\"\\nsam = sam_model_registry[model_type](checkpoint=checkpoint).cuda()\\npredictor = SamPredictor(sam)\\n\\n# Function to draw bounding boxes and masks on the image\\ndef draw_boxes_and_masks(original_image, rois, masks, mask_opacity=0.5):\\n    original_image = original_image.convert(\"RGBA\")\\n    mask_image = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\\n    \\n    for i, roi in enumerate(rois):\\n        y1, x1, y2, x2 = roi\\n        draw = ImageDraw.Draw(original_image)\\n        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\\n\\n        mask = masks[i]\\n        mask_image_part = Image.fromarray((mask * 255).astype(np.uint8)).convert(\"L\")\\n        mask_with_opacity = Image.new(\"RGBA\", mask_image.size, (255, 255, 255, 0))\\n        \\n        for x in range(mask_image_part.width):\\n            for y in range(mask_image_part.height):\\n                if mask_image_part.getpixel((x, y)) > 0:\\n                    mask_with_opacity.putpixel((x, y), (255, 0, 0, int(255 * mask_opacity)))\\n        \\n        mask_image = Image.alpha_composite(mask_image, mask_with_opacity)\\n\\n    return Image.alpha_composite(original_image, mask_image).convert(\"RGB\")\\n\\n\\n# Function to run the prediction\\ndef run_prediction(img_file):\\n    target_size = (224, 224)\\n    image = skimage.io.imread(img_file)\\n    image = remove_alpha_channel(image)\\n\\n    results = model.detect([image], verbose=1)\\n    r = results[0]\\n    \\n    confidence_threshold = 0.9\\n    filtered_indices = np.where(r[\\'scores\\'] >= confidence_threshold)[0]\\n    filtered_rois = r[\\'rois\\'][filtered_indices]\\n    \\n    predictor.set_image(image)\\n    filtered_rois_xyxy = transform_yxyx_to_xyxy(filtered_rois)\\n    input_boxes = torch.tensor(filtered_rois_xyxy, device=predictor.device)\\n    transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])  \\n\\n    save_path = \"/kaggle/working/cropped\"\\n    os.makedirs(save_path, exist_ok=True)\\n    \\n    masks_list = []\\n    \\n    for j, box in enumerate(transformed_boxes):\\n        masks, scores, _ = predictor.predict_torch(\\n            boxes=torch.unsqueeze(box, 0),\\n            point_coords=None,\\n            point_labels=None,\\n            multimask_output=True\\n        )\\n\\n        if masks.shape[0] > 0:\\n            highest_score_index = torch.argmax(scores)\\n            highest_score_mask = masks[0][highest_score_index].cpu().numpy()\\n            masks_list.append(highest_score_mask)\\n            \\n            cropped_image = crop_object_from_image(image, highest_score_mask)\\n\\n            if cropped_image is None:\\n                print(f\"No object found in mask {j} for image {img_file}\")\\n                continue\\n\\n            resized_padded_image = resize_and_pad_image(cropped_image, target_size)\\n            filename = os.path.splitext(os.path.basename(img_file))[0]\\n            skimage.io.imsave(os.path.join(save_path, f\\'cropped_image_{filename}_{j}.png\\'), resized_padded_image)\\n        else:\\n            print(f\"No masks returned for box {j} in image {img_file}\")\\n\\n    original_image = Image.fromarray(image)\\n    \\n    if masks_list:\\n        image_with_boxes = draw_boxes_and_masks(original_image.copy(), filtered_rois, masks_list)\\n    else:\\n        image_with_boxes = original_image.copy()\\n\\n    return image_with_boxes\\n\\n\\n# Create widgets for the interface\\nfile_upload = widgets.FileUpload(accept=\\'.jpg,.jpeg,.png\\', multiple=False)\\noutput = widgets.Output()\\n\\n# Function to handle file upload and display prediction\\ndef on_file_upload(change):\\n    for file_name, file_info in file_upload.value.items():\\n        with output:\\n            output.clear_output()\\n            \\n            img_data = file_info[\\'content\\']\\n            img = Image.open(io.BytesIO(img_data))\\n            img.thumbnail((244, 244))\\n            \\n            # Display original image\\n            display(widgets.Image(value=img_data, format=\\'png\\'))\\n            \\n            # Save to disk for model processing\\n            img_path = f\"/kaggle/working/{file_name}\"\\n            with open(img_path, \\'wb\\') as f:\\n                f.write(img_data)\\n            \\n            # Run the prediction\\n            image_with_boxes = run_prediction(img_path)\\n            \\n            # Display processed image with boxes\\n            processed_img_bytes = io.BytesIO()\\n            image_with_boxes.save(processed_img_bytes, format=\\'PNG\\')\\n            processed_img_bytes.seek(0)\\n            display(widgets.Image(value=processed_img_bytes.read(), format=\\'png\\'))\\n\\n\\nfile_upload.observe(on_file_upload, names=\\'value\\')\\n\\n# Display the UI\\ndisplay(file_upload, output)\\n'"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display\nfrom PIL import Image, ImageDraw\nimport numpy as np\nimport torch\nimport skimage.io\nimport io\nimport os\nfrom mrcnn.config import Config\nfrom mrcnn.model import MaskRCNN\nfrom segment_anything import SamPredictor, sam_model_registry\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module='keras.engine.training_v1')\n\n\n# Load the Mask R-CNN model\nclass InferenceConfig(Config):\n    NAME = \"coco\"\n    IMAGES_PER_GPU = 1\n    NUM_CLASSES = 1 + 1  # Background + coconut\n    GPU_COUNT = 1\n\nconfig = InferenceConfig()\nmodel = MaskRCNN(mode=\"inference\", model_dir=\"/path/to/logs\", config=config)\nmodel.load_weights(\"/kaggle/input/cocooo/mask_rcnn_custom_0015.h5\", by_name=True)\n\ncheckpoint = \"/kaggle/input/samvith/sam_vit_h_4b8939.pth\"\nmodel_type = \"vit_h\"\nsam = sam_model_registry[model_type](checkpoint=checkpoint).cuda()\npredictor = SamPredictor(sam)\n\n# Function to draw bounding boxes and masks on the image\ndef draw_boxes_and_masks(original_image, rois, masks, mask_opacity=0.5):\n    original_image = original_image.convert(\"RGBA\")\n    mask_image = Image.new(\"RGBA\", original_image.size, (0, 0, 0, 0))\n    \n    for i, roi in enumerate(rois):\n        y1, x1, y2, x2 = roi\n        draw = ImageDraw.Draw(original_image)\n        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n\n        mask = masks[i]\n        mask_image_part = Image.fromarray((mask * 255).astype(np.uint8)).convert(\"L\")\n        mask_with_opacity = Image.new(\"RGBA\", mask_image.size, (255, 255, 255, 0))\n        \n        for x in range(mask_image_part.width):\n            for y in range(mask_image_part.height):\n                if mask_image_part.getpixel((x, y)) > 0:\n                    mask_with_opacity.putpixel((x, y), (255, 0, 0, int(255 * mask_opacity)))\n        \n        mask_image = Image.alpha_composite(mask_image, mask_with_opacity)\n\n    return Image.alpha_composite(original_image, mask_image).convert(\"RGB\")\n\n\n\n# Function to run the prediction\ndef run_prediction(img_file):\n    target_size = (224, 224)\n    image = skimage.io.imread(img_file)\n    image = remove_alpha_channel(image)\n\n    results = model.detect([image], verbose=1)\n    r = results[0]\n    \n    confidence_threshold = 0.9\n    filtered_indices = np.where(r['scores'] >= confidence_threshold)[0]\n    filtered_rois = r['rois'][filtered_indices]\n    \n    predictor.set_image(image)\n    filtered_rois_xyxy = transform_yxyx_to_xyxy(filtered_rois)\n    input_boxes = torch.tensor(filtered_rois_xyxy, device=predictor.device)\n    transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])  \n\n    save_path = \"/kaggle/working/cropped\"\n    os.makedirs(save_path, exist_ok=True)\n    \n    cropped_images = []\n    masks_list = []\n    \n    for j, box in enumerate(transformed_boxes):\n        masks, scores, _ = predictor.predict_torch(\n            boxes=torch.unsqueeze(box, 0),\n            point_coords=None,\n            point_labels=None,\n            multimask_output=True\n        )\n\n        if masks.shape[0] > 0:\n            highest_score_index = torch.argmax(scores)\n            highest_score_mask = masks[0][highest_score_index].cpu().numpy()\n            masks_list.append(highest_score_mask)\n            \n            cropped_image = crop_object_from_image(image, highest_score_mask)\n\n            if cropped_image is None:\n                print(f\"No object found in mask {j} for image {img_file}\")\n                continue\n\n            resized_padded_image = resize_and_pad_image(cropped_image, target_size)\n            cropped_images.append(resized_padded_image)\n            \n            filename = os.path.splitext(os.path.basename(img_file))[0]\n            skimage.io.imsave(os.path.join(save_path, f'cropped_image_{filename}_{j}.png'), resized_padded_image)\n        else:\n            print(f\"No masks returned for box {j} in image {img_file}\")\n\n    original_image = Image.fromarray(image)\n    \n    if masks_list:\n        image_with_boxes = draw_boxes_and_masks(original_image.copy(), filtered_rois, masks_list)\n    else:\n        image_with_boxes = original_image.copy()\n\n    return image_with_boxes, cropped_images\n\n\n\n# Create widgets for the interface\nfile_upload = widgets.FileUpload(accept='.jpg,.jpeg,.png', multiple=False)\noutput = widgets.Output()\n\n# Function to handle file upload and display prediction\ndef on_file_upload(change):\n    for file_name, file_info in file_upload.value.items():\n        with output:\n            output.clear_output()\n            \n            img_data = file_info['content']\n            img = Image.open(io.BytesIO(img_data))\n            img.thumbnail((244, 244))\n            \n            # Display original image\n            original_img_widget = widgets.Image(value=img_data, format='png')\n            \n            # Save to disk for model processing\n            img_path = f\"/kaggle/working/{file_name}\"\n            with open(img_path, 'wb') as f:\n                f.write(img_data)\n            \n            # Run the prediction\n            image_with_boxes, cropped_images = run_prediction(img_path)\n            \n            # Display processed image with boxes\n            processed_img_bytes = io.BytesIO()\n            image_with_boxes.save(processed_img_bytes, format='PNG')\n            processed_img_bytes.seek(0)\n            processed_img_widget = widgets.Image(value=processed_img_bytes.read(), format='png')\n            \n            # Display original and processed images side by side using HBox\n            display(widgets.HBox([original_img_widget, processed_img_widget]))\n            \n            # Display cropped images below\n            if cropped_images:\n                cropped_widgets = []\n                for cropped_img in cropped_images:\n                    cropped_img_bytes = io.BytesIO()\n                    skimage.io.imsave(cropped_img_bytes, cropped_img, format='png')\n                    cropped_img_bytes.seek(0)\n                    cropped_widget = widgets.Image(value=cropped_img_bytes.read(), format='png')\n                    cropped_widgets.append(cropped_widget)\n\n                display(widgets.HBox(cropped_widgets))\n\nfile_upload.observe(on_file_upload, names='value')\n\n# Display the UI\ndisplay(file_upload, output)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-12T02:28:44.654047Z","iopub.execute_input":"2024-11-12T02:28:44.654561Z","iopub.status.idle":"2024-11-12T02:29:24.982426Z","shell.execute_reply.started":"2024-11-12T02:28:44.654509Z","shell.execute_reply":"2024-11-12T02:29:24.981438Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-11-12 02:28:48.874899: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-11-12 02:28:48.875681: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-11-12 02:28:48.875768: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(f)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"FileUpload(value={}, accept='.jpg,.jpeg,.png', description='Upload')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f6898db6117491c88df4d2ca19e26cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a206776219df4daab4cb88a0cf22f653"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}